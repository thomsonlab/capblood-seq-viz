{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import capblood_seq\n",
    "from capblood_seq import config\n",
    "\n",
    "import pickle\n",
    "\n",
    "SEED=1040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset. This downloads it if it doesn't exist already, and loads it into memory\n",
    "dataset = capblood_seq.load_dataset(data_directory=\"data\", pipeline_name=\"visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the combined tSNE, we want to get all cells across all samples and store their\n",
    "# originating sample and subject for plotting\n",
    "\n",
    "# A matrix containing the gene expression across all samples\n",
    "combined_transcript_counts = []\n",
    "\n",
    "cell_data = []\n",
    "\n",
    "for sample_index, sample in enumerate(config.SAMPLE_NAMES):        \n",
    "    \n",
    "    if \"AM\" in sample:\n",
    "        sample_time_of_day = \"AM\"\n",
    "    elif \"PM\" in sample:\n",
    "        sample_time_of_day = \"PM\"\n",
    "    \n",
    "    ged = dataset._sample_datasets[sample]\n",
    "    label_cells = dataset._sample_datasets[sample].get_label_cells()\n",
    "    \n",
    "    cell_transcript_counts = ged.get_cell_transcript_counts()\n",
    "    \n",
    "    for cell_barcode in cell_transcript_counts.row_names:\n",
    "        \n",
    "        subject_id_to_append = None\n",
    "        \n",
    "        for subject_id in config.SUBJECT_IDS:\n",
    "            \n",
    "            if subject_id in label_cells:\n",
    "                \n",
    "                if cell_barcode in label_cells[subject_id]:\n",
    "                    subject_id_to_append = subject_id\n",
    "                    break\n",
    "\n",
    "        cell_types = []\n",
    "                    \n",
    "        for cell_type in config.CELL_TYPES:\n",
    "\n",
    "            if cell_barcode in dataset.get_cells(sample, cell_type=cell_type):\n",
    "                cell_types.append(cell_type)\n",
    "\n",
    "            if cell_type in config.CELL_SUBTYPES:\n",
    "                for cell_subtype in config.CELL_SUBTYPES[cell_type]:\n",
    "                    cell_subtype_label = \"%s %s\" % (cell_subtype, cell_type)\n",
    "                    if cell_barcode in dataset.get_cells(sample, cell_type=cell_subtype_label):\n",
    "                        cell_types.append(cell_subtype_label)\n",
    "\n",
    "        cell_types = \";\".join(cell_types)\n",
    "\n",
    "        if subject_id_to_append is not None:\n",
    "            gender = config.SUBJECT_ID_GENDERS[subject_id_to_append]\n",
    "        else:\n",
    "            gender = None\n",
    "            \n",
    "        cell_row = (cell_barcode, sample, sample_time_of_day, subject_id_to_append, gender, cell_types)\n",
    "\n",
    "        cell_data.append(cell_row)\n",
    "        \n",
    "    cell_transcript_counts = cell_transcript_counts.to_array()\n",
    "    \n",
    "    # Add these cell transcript counts to the combined matrix\n",
    "    combined_transcript_counts.append(cell_transcript_counts)\n",
    "\n",
    "combined_transcript_counts = numpy.concatenate(\n",
    "   combined_transcript_counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze variationan autoencoder and training parameters\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "# Save the training weights\n",
    "latent_pickle_file_name = os.path.join(dataset.data_directory, \"Dobreva2020\", \"dobreva2020_nepoch_%i_lr_%.1e_latent.pickle\" % (n_epochs, learning_rate))\n",
    "\n",
    "# Transform the normalized gene expression values into PCA space\n",
    "with open(latent_pickle_file_name, 'rb') as latent_pickle_file:\n",
    "    latent = pickle.load(latent_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the combined PCA coordinates into t-SNE space\n",
    "combined_cell_coordinates = TSNE(\n",
    "    verbose=True,\n",
    "    perplexity=30,\n",
    "    n_components=2,\n",
    "    random_state=SEED\n",
    ").fit_transform(\n",
    "    latent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_df = pandas.DataFrame.from_records(\n",
    "    cell_data,\n",
    "    columns=[\"Cell Barcode\", \"Sample\", \"Time of Day\", \"Subject ID\", \"Gender\", \"Cell Type(s)\"]\n",
    ")\n",
    "cell_data_df[\"t-SNE x\"] = combined_cell_coordinates[:, 0]\n",
    "cell_data_df[\"t-SNE y\"] = combined_cell_coordinates[:, 1]\n",
    "cell_data_df.to_csv(os.path.join(\"data\", \"cell_tSNE_coordinates_metadata.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
